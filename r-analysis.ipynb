{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Talkspace is an online, text-based therapy service. I have been using the service for about a year, and over that time, I've noticed it's sometimes hard for me to stay engaged. There have been long stretches of times where I have not responded to my therapist. [Patient engagement is critical to developing a therapeutic relationship](http://dx.doi.org/10.3389/fpsyg.2015.02013), so if I can increase my own responsiveness, I might increase the efficacy of my therapy.\n",
    "\n",
    "Unfortunately, Talkspace hasn't provided me with any kind of patient engagemnt questionaire (such as the [Patient Activation Measure](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1361049/)), so I don't have any existing historical measures of enagement. The metrics most accessible to me that I might want to optimize for are my response time and how many words I write to my therapist per day I take to respond, i.e.\n",
    "\n",
    "$$\n",
    "\\frac{\\textrm{word count of message}}{\\textrm{time it takes me to write the message}}\n",
    "$$\n",
    "\n",
    "These quantities will obviously vary, and my suspicion is that some of that variability can be explained. If I can find a statistically significant factor that partly explains the variability, I'll have a lever to pull to improve my therapeutic relationship and my own mental health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data (you can do this too!)\n",
    "Prior to this analysis, I wrote an [tool](https://github.com/vaughn-johnson/talkspace-scraper) to allow anyone to scrape his or her Talkspace message history. If you are familiar with Javascript and NPM, you can use the tool to save that data to a database or export it directly as a file.\n",
    "\n",
    "This is obviously _highly sensitive data_. You should __never__ give your Talkspace username and password to a third party you do not trust. If you choose to use this tool, please exercise caution by [reviewing the code first](https://github.com/vaughn-johnson/talkspace-scraper). I appreciate that this stipulation might make the tool less accessible, but I strongly discourage anyone from blindly using this tool without being sure that his or her username and password will be secure.\n",
    "\n",
    "With that being said, here I am importing my own data from my own database. If you're unfamiliar with `dotenv`, I would _highly_ encourae reading about it [here](https://pypi.org/project/python-dotenv/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(mongolite)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(dotenv)\n",
    "library(tidyr)\n",
    "library(quanteda)\n",
    "library(lubridate)\n",
    "library(GGally)\n",
    "library(rio)\n",
    "\n",
    "load_dot_env()\n",
    "options(repr.plot.width=15, repr.plot.height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " Found 612 records...\r",
      " Imported 612 records. Simplifying into dataframe...\n"
     ]
    }
   ],
   "source": [
    "# If you don't have access to this private database, you can see access the results at the api called below\n",
    "mongo_response = mongo(\n",
    "    collection = \"messages\",\n",
    "    url = Sys.getenv(\"MONGO_CONNECTION_STRING\"),\n",
    "    verbose = TRUE,\n",
    "    options = ssl_options(weak_cert_validation = FALSE, allow_invalid_hostname = FALSE)\n",
    ")$find(\n",
    "    '{ \"message_type\": { \"$in\": [1] } }', #other message types include automated messages from Talkspace\n",
    "    '{ \"message\": 1, \"display_name\": 1, \"created_at\": 1 }'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = mongo_response %>%\n",
    "           mutate(created_at = as_datetime(created_at)) %>%\n",
    "\n",
    "           # Clean up messages\n",
    "           mutate(message = gsub('.*> ', '', message)) %>%\n",
    "           mutate(message = gsub('(Vaughn,\\n*|Respectfully,[\\n ]*Dallas)', '', message)) %>%\n",
    "           mutate(message = gsub('\\n\\n+', '\\n', message)) %>%\n",
    "\n",
    "           # Make this more usable by others\n",
    "           mutate(display_name = recode(display_name, 'Vaughn' = 'Me', 'Dallas' = 'My Therapist')) %>%\n",
    "\n",
    "           # Sort by send date\n",
    "           arrange(created_at) %>%\n",
    "        \n",
    "           # Group consecutive messages from the same person into blocks\n",
    "           mutate(message_block = cumsum(display_name != replace_na(lag(display_name), 'Me')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGES_API = 'https://us-central1-talkspace-293821.cloudfunctions.net/talkspace-public-api?format=csv'\n",
    "\n",
    "messages = rio::import(MESSAGES_API, format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_blocks = messages %>%\n",
    "                 # Concatenate consecutive messages\n",
    "                 group_by(message_block) %>%\n",
    "                 summarise(display_name = min(display_name),\n",
    "                           created_at = min(created_at),\n",
    "                           message = paste(message, collapse='')) %>%\n",
    "                 \n",
    "                 mutate(message_length = nchar(message)) %>%\n",
    "                 mutate(word_count = stringr::str_count(message, ' ') + 1) %>%\n",
    "                 mutate(question_count = stringr::str_count(message, '\\\\?')) %>%\n",
    "                 mutate(readability = textstat_readability(message, measure=c('Flesch'))$Flesch) %>%\n",
    "                 drop_na() %>%\n",
    "                 mutate(response_time = time_length(lag(created_at) %--% created_at, unit='days')) %>%\n",
    "                 mutate(words_per_day = word_count / time_length(response_time, unit='days')) %>%\n",
    "\n",
    "                 mutate(prev_message_length = lag(message_length)) %>%\n",
    "                 mutate(prev_word_count = lag(word_count)) %>%\n",
    "                 mutate(prev_question_count = lag(question_count)) %>%\n",
    "                 mutate(prev_readability = lag(readability))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "First, let's just look at the distribution of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(message_blocks, aes(x=readability, fill=display_name, title='Flesch Reading Ease Score of Messages')) +\n",
    "    geom_histogram() +\n",
    "    facet_wrap('display_name', dir = 'v') +\n",
    "    xlab('Readability') +\n",
    "    theme_minimal() +\n",
    "    ggtitle('Flesch Reading Ease Score of Messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(message_blocks, aes(x=question_count, fill=display_name, title='Flesch Reading Ease Score of Messages')) +\n",
    "    geom_histogram() +\n",
    "    facet_wrap('display_name', dir = 'v') +\n",
    "    xlab('Question Count') +\n",
    "    theme_minimal() +\n",
    "    ggtitle('Number of questions asked (measured by appearence of \\\"?\\\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the quantities I'm trying to optimize for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(message_blocks, aes(x=words_per_day, fill=display_name, title='Flesch Reading Ease Score of Messages')) +\n",
    "    geom_histogram() +\n",
    "    facet_wrap('display_name', dir = 'v') +\n",
    "    xlab('Words per Day') +\n",
    "    theme_minimal() +\n",
    "    ggtitle('How many words typed per day it took to respond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(message_blocks, aes(x=response_time, fill=display_name, title='Flesch Reading Ease Score of Messages')) +\n",
    "    geom_histogram() +\n",
    "    facet_wrap('display_name', dir = 'v') +\n",
    "    xlab('Response Time') +\n",
    "    theme_minimal() +\n",
    "    ggtitle('Time to respond (in days)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(My therapist Dallas has much shorter response times than me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some pair-wise plots of some of the featues I've extracted above that I think might explain how I interact with my therapist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_cols = c(\n",
    "    \"words_per_day\",\n",
    "    \"response_time\",\n",
    "    \"prev_word_count\",\n",
    "    \"prev_question_count\",\n",
    "    \"prev_readability\"\n",
    ")\n",
    "\n",
    "\n",
    "ggpairs(message_blocks[c('display_name', pair_cols)], aes(color=display_name, alpha=0.4)) +\n",
    "    theme_minimal() +\n",
    "    ggtitle('Response data (Each point is a message, \"Prev\" means the previous message the point is responding to)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing incredibly interesting jumps out here. We see some normally distributed varaibles plotted against uniformly distributed variables, which of course produces a bell shape. There isn't a clear relationship anywhere. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the characteristics of my therapist's messages explain my responsiveness?\n",
    "\n",
    "Let's try to develop a model that tries to explain my responsiveness based on the messages I'm responding to. My hypothesis is that I might take longer to respond to more complex messages. Messages with a lower readability score, which are longer, or which ask me more question. I think if these were going to have have any affect, it would probably be linear, so fitting a generalized linear model with least squares seems appropriate.\n",
    "\n",
    "To be clear, this data is _not_ well suited for linear regression. The response variable I'm interested in does not appear to be normally distributed with any of its covariates, and the covariants aren't perfectly non-collinear. The observations are obviously not independent (though they don't seem to show any obvious autocorrelation). However, I think it's ok to give it a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_messages = message_blocks %>% filter(display_name == 'Me')  %>% drop_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf((my_messages)$response_time, main = 'Auto correlation of my response times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf((my_messages)$words_per_day, main = 'Auto correlation of my words per day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.glm(glm(\"response_time ~ prev_word_count + prev_question_count + prev_readability\", family='gaussian', my_messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of that regression _clearly_ shows a very poor fit. I feel comfortable continuing on with the hypothesis that my therapist's messages have no effect on my responses.\n",
    "\n",
    "I'll fit and test a second model, but instead of predicting `words per day`, I'll predict how long it takes me to respond (using the same covariates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.glm(glm(\"words_per_day ~ prev_word_count + prev_question_count + prev_readability\", family='gaussian', my_messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second model is a little more significant, and worlds apart a better fit than the previous model. It seems like the length of my therapist's previous messages might have an effect on how long it takes me to respond. The point estimate is `0.0037`, which with the units we're using, means for every additional word my therapist send me, it takes me something on the order of 5 and a half minutes longer respond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "There are two interacting conclusions from this\n",
    "1. Nothing that I looked at today from my therapists messages makes me send more messages per unit time\n",
    "2. The longer my therapist's messages are, the longer it takes me to respond\n",
    "\n",
    "What this really means is that there is some _compensatory_ effect between how long it takes me to respond to my therapist, and how much I write back, and that compensatory effect washes out any measurable effect from the length of the message I'm responding to. If my therapist sends me a long message, I will generally take longer, but respond with a longer message. This actually shows up as a slight correlation between my response time and word count (`r = 0.325`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(my_messages$response_time, my_messages$word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(my_messages, aes(x=response_time, y=word_count)) +\n",
    "    geom_point() +\n",
    "    geom_smooth(method = \"lm\") +\n",
    "    theme_minimal() +\n",
    "    xlab('Respone Time (days)') +\n",
    "    ylab('Word Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and next steps\n",
    "\n",
    "I have a new rule of thumb for my therapist. For every additional paragraph you send me, you can expect an additional 18 hours or so for me to respond. However, when I finally do respond, my response will generally be slightly longer.\n",
    "\n",
    "## Next steps\n",
    "I would like to build out a language model of these messages. Sometimes my therapist characterizes some of the things I send to him as good or bad, and it would be fabulous to build a model that could predict that judgement on arbitrary text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:talkspace-r] *",
   "language": "R",
   "name": "conda-env-talkspace-r-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
